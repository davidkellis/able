package regex
import able.kernel.{Array, __able_String_from_builtin, __able_String_to_builtin}
import able.collections.hash_map.{HashMap}
import able.core.interfaces.{Error}
import able.core.iteration.{Iterator, IteratorEnd}
import able.core.options.{Result}

struct Span {
  start: u64,
  end: u64
}

struct RegexOptions {
  case_insensitive: bool,
  multiline: bool,
  dot_matches_newline: bool,
  unicode: bool,
  anchored: bool,
  unicode_case: bool,
  grapheme_mode: bool
}

methods RegexOptions {
  fn default() -> RegexOptions {
    RegexOptions {
      case_insensitive: false,
      multiline: false,
      dot_matches_newline: false,
      unicode: true,
      anchored: false,
      unicode_case: false,
      grapheme_mode: false
    }
  }
}

struct RegexToken {
  byte: u8,
  min: i32,
  max: i32
}

struct RegexHandle {
  tokens: Array RegexToken
}

struct Regex {
  pattern: String,
  options: RegexOptions,
  program: RegexHandle
}

struct RegexInvalidPattern {
  message: String,
  span: Span
}

struct RegexUnsupportedFeature {
  message: String,
  hint: ?String
}

struct RegexCompileFailure {
  message: String
}

union RegexError =
  RegexInvalidPattern |
  RegexUnsupportedFeature |
  RegexCompileFailure

impl Error for RegexInvalidPattern {
  fn message(self: Self) -> String { self.message }
  fn cause(self: Self) -> ?Error { nil }
}

impl Error for RegexUnsupportedFeature {
  fn message(self: Self) -> String { self.message }
  fn cause(self: Self) -> ?Error { nil }
}

impl Error for RegexCompileFailure {
  fn message(self: Self) -> String { self.message }
  fn cause(self: Self) -> ?Error { nil }
}

fn unsupported(feature: String) -> RegexUnsupportedFeature {
  RegexUnsupportedFeature {
    message: `regex ${feature} is not implemented yet`,
    hint: nil
  }
}

fn validate_options(options: RegexOptions) -> ?RegexUnsupportedFeature {
  if options.unicode == false { return unsupported("unicode=false") }
  if options.anchored { return unsupported("anchored") }
  if options.unicode_case { return unsupported("unicode_case") }
  if options.grapheme_mode { return unsupported("grapheme_mode") }
  nil
}

fn to_u64(value: i32) -> u64 {
  if value <= 0 { 0 } else { value }
}

fn clamp_offset(offset: u64, len: i32) -> i32 {
  if len <= 0 { return 0 }
  if offset > to_u64(len) { len } else { offset as i32 }
}

fn invalid_pattern(message: String, start: i32, end: i32) -> RegexInvalidPattern {
  RegexInvalidPattern { message, span: Span { start: to_u64(start), end: to_u64(end) } }
}

fn is_unsupported_meta(byte: u8) -> bool {
  (
    byte == 36_u8 || byte == 40_u8 || byte == 41_u8 ||
    byte == 46_u8 || byte == 91_u8 || byte == 93_u8 ||
    byte == 94_u8 || byte == 124_u8
  )
}

fn is_quantifier_byte(byte: u8) -> bool {
  byte == 42_u8 || byte == 43_u8 || byte == 63_u8 || byte == 123_u8 || byte == 125_u8
}

struct NumberParse {
  value: i32,
  next: i32
}

fn parse_number(bytes: Array u8, start: i32) -> ?NumberParse {
  idx := start
  if idx >= bytes.len() { return nil }
  digit := bytes.read_slot(idx)
  if digit < 48_u8 || digit > 57_u8 { return nil }
  value := 0
  loop {
    if idx >= bytes.len() { break }
    digit = bytes.read_slot(idx)
    if digit < 48_u8 || digit > 57_u8 { break }
    value = value * 10 + (digit as i32 - 48)
    idx = idx + 1
  }
  NumberParse { value, next: idx }
}

fn parse_tokens(pattern: String) -> Result (Array RegexToken) {
  bytes := __able_String_from_builtin(pattern)
  tokens: Array RegexToken := Array.new()
  idx := 0
  loop {
    if idx >= bytes.len() { break }
    byte := bytes.read_slot(idx)
    escaped := false
    if byte == 92_u8 {
      idx = idx + 1
      if idx >= bytes.len() {
        return invalid_pattern("dangling escape", idx - 1, idx)
      }
      byte = bytes.read_slot(idx)
      escaped = true
    }
    if !escaped {
      if is_quantifier_byte(byte) {
        return invalid_pattern("quantifier missing atom", idx, idx + 1)
      }
      if is_unsupported_meta(byte) {
        return unsupported("pattern metacharacters")
      }
    }
    min := 1
    max := 1
    if idx + 1 < bytes.len() {
      next := bytes.read_slot(idx + 1)
      if next == 42_u8 {
        min = 0
        max = -1
        idx = idx + 1
      } elsif next == 43_u8 {
        min = 1
        max = -1
        idx = idx + 1
      } elsif next == 63_u8 {
        min = 0
        max = 1
        idx = idx + 1
      } elsif next == 123_u8 {
        quant_start := idx + 1
        parse_number(bytes, idx + 2) match {
          case nil => { return invalid_pattern("invalid quantifier", quant_start, quant_start + 1) },
          case parsed: NumberParse => {
            min = parsed.value
            idx = parsed.next
            if idx >= bytes.len() {
              return invalid_pattern("unterminated quantifier", quant_start, idx)
            }
            byte = bytes.read_slot(idx)
            if byte == 125_u8 {
              max = min
            } elsif byte == 44_u8 {
              if idx + 1 >= bytes.len() {
                return invalid_pattern("unterminated quantifier", quant_start, idx + 1)
              }
              if bytes.read_slot(idx + 1) == 125_u8 {
                max = -1
                idx = idx + 1
              } else {
                parse_number(bytes, idx + 1) match {
                  case nil => { return invalid_pattern("invalid quantifier", quant_start, idx + 1) },
                  case parsed_max: NumberParse => {
                    max = parsed_max.value
                    idx = parsed_max.next
                  }
                }
                if idx >= bytes.len() || bytes.read_slot(idx) != 125_u8 {
                  return invalid_pattern("unterminated quantifier", quant_start, idx)
                }
              }
            } else {
              return invalid_pattern("invalid quantifier", quant_start, idx + 1)
            }
          }
        }
      }
    }
    tokens.push(RegexToken { byte, min, max })
    idx = idx + 1
  }
  tokens
}

fn match_from(tokens: Array RegexToken, token_idx: i32, haystack: Array u8, pos: i32) -> ?i32 {
  if token_idx >= tokens.len() { return pos }
  tokens.get(token_idx) match {
    case nil => pos,
    case token: RegexToken => {
      hay_len := haystack.len()
      max_run := 0
      loop {
        if pos + max_run >= hay_len { break }
        if haystack.read_slot(pos + max_run) != token.byte { break }
        if token.max >= 0 && max_run >= token.max { break }
        max_run = max_run + 1
      }
      if max_run < token.min { return nil }
      run := max_run
      loop {
        if run < token.min { break }
        match_from(tokens, token_idx + 1, haystack, pos + run) match {
          case nil => {},
          case end: i32 => { return end }
        }
        run = run - 1
      }
      nil
    }
  }
}

fn find_token_span(tokens: Array RegexToken, haystack: Array u8, start: i32) -> ?Span {
  pos := start
  if pos < 0 { pos = 0 }
  if tokens.len() == 0 {
    if pos > haystack.len() { return nil }
    return Span { start: to_u64(pos), end: to_u64(pos) }
  }
  loop {
    if pos > haystack.len() { break }
    match_from(tokens, 0, haystack, pos) match {
      case nil => { pos = pos + 1 },
      case end: i32 => { return Span { start: to_u64(pos), end: to_u64(end) } }
    }
  }
  nil
}

fn slice_bytes(bytes: Array u8, start: i32, end: i32) -> Array u8 {
  capacity := 0
  if end > start { capacity = end - start }
  result: Array u8 := Array.with_capacity(capacity)
  idx := start
  loop {
    if idx >= end { break }
    result.push(bytes.read_slot(idx))
    idx = idx + 1
  }
  result
}

fn build_match(haystack: Array u8, span: Span) -> Match {
  start := clamp_offset(span.start, haystack.len())
  end := clamp_offset(span.end, haystack.len())
  Match {
    matched: __able_String_to_builtin(slice_bytes(haystack, start, end)),
    span,
    groups: Array.new(),
    named_groups: HashMap.new()
  }
}

struct Group {
  name: ?String,
  value: ?String,
  span: ?Span
}

struct Match {
  matched: String,
  span: Span,
  groups: Array Group,
  named_groups: HashMap String Group
}

union Replacement =
  ReplacementLiteral String |
  ReplacementFunction (Match -> String)

struct RegexIter {
  haystack: String,
  regex: Regex,
  offset: u64,
  done: bool
}

impl Iterator Match for RegexIter {
  fn next(self: Self) -> Match | IteratorEnd {
    if self.done { return IteratorEnd {} }
    hay_bytes := __able_String_from_builtin(self.haystack)
    start := clamp_offset(self.offset, hay_bytes.len())
    tokens := self.regex.program.tokens
    find_token_span(tokens, hay_bytes, start) match {
      case nil => {
        self.done = true
        IteratorEnd {}
      },
      case span: Span => {
        result := build_match(hay_bytes, span)
        next_offset := span.end
        if span.end == span.start { next_offset = next_offset + 1_u64 }
        if next_offset > to_u64(hay_bytes.len()) {
          self.done = true
        } else {
          self.offset = next_offset
        }
        result
      }
    }
  }
}

struct RegexSet {
  patterns: Array Regex
}

struct RegexScanner {
  regex: Regex,
  buffer: String,
  offset: u64
}

methods RegexScanner {
  fn feed(self: Self, chunk: String) -> void {
    self.buffer = `${self.buffer}${chunk}`
  }

  fn next(self: Self) -> Match | IteratorEnd {
    hay_bytes := __able_String_from_builtin(self.buffer)
    start := clamp_offset(self.offset, hay_bytes.len())
    tokens := self.regex.program.tokens
    find_token_span(tokens, hay_bytes, start) match {
      case nil => IteratorEnd {},
      case span: Span => {
        result := build_match(hay_bytes, span)
        next_offset := span.end
        if span.end == span.start { next_offset = next_offset + 1_u64 }
        if next_offset > to_u64(hay_bytes.len()) {
          self.offset = to_u64(hay_bytes.len())
        } else {
          self.offset = next_offset
        }
        result
      }
    }
  }
}

methods Regex {
  fn compile(pattern: String) -> Regex | Error {
    Regex.compile_with_options(pattern, RegexOptions.default())
  }

  fn compile_with_options(pattern: String, options: RegexOptions) -> Regex | Error {
    validate_options(options) match {
      case err: RegexUnsupportedFeature => err,
      case nil => parse_tokens(pattern) match {
        case err: Error => err,
        case tokens: Array RegexToken => Regex {
          pattern,
          options,
          program: RegexHandle { tokens: tokens }
        }
      }
    }
  }

  fn is_match(self: Self, haystack: String) -> bool {
    self.match(haystack) match {
      case nil => false,
      case _: Match => true
    }
  }

  fn match(self: Self, haystack: String) -> ?Match {
    hay_bytes := __able_String_from_builtin(haystack)
    tokens := self.program.tokens
    find_token_span(tokens, hay_bytes, 0) match {
      case nil => nil,
      case span: Span => build_match(hay_bytes, span)
    }
  }

  fn find_all(self: Self, haystack: String) -> RegexIter {
    RegexIter { haystack, regex: self, offset: 0, done: false }
  }

  fn replace(self: Self, haystack: String, replacement: Replacement) -> Result String {
    unsupported("replace")
  }

  fn split(self: Self, haystack: String, limit: ?u64) -> Array String {
    raise unsupported("split")
  }

  fn scan(self: Self, haystack: String) -> RegexScanner {
    RegexScanner { regex: self, buffer: haystack, offset: 0 }
  }
}

fn regex_is_match(pattern: String, haystack: String) -> Result bool {
  Regex.compile(pattern) match {
    case err: Error => err,
    case regex: Regex => regex.is_match(haystack)
  }
}
